{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embedding model creation using NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Dense, Flatten\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sent = ['Hello, how are you',\n",
    "        'how are you',\n",
    "        'how are you doing',\n",
    "        'I am doing great',\n",
    "        'I am doing good',\n",
    "        'I am good']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_labels = np.array([0,0,0,1,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3, 4, 12, 5], [4, 12, 5], [4, 12, 5, 16], [6, 26, 16, 17], [6, 26, 16, 25], [6, 26, 25]]\n"
     ]
    }
   ],
   "source": [
    "my_vocab = 30\n",
    "encoding_sentence = [one_hot(i, my_vocab)  for i in Sent]\n",
    "print(encoding_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  3  4 12  5]\n",
      " [ 0  0  4 12  5]\n",
      " [ 0  4 12  5 16]\n",
      " [ 0  6 26 16 17]\n",
      " [ 0  6 26 16 25]\n",
      " [ 0  0  6 26 25]]\n"
     ]
    }
   ],
   "source": [
    "length = 5\n",
    "padded_sentence = pad_sequences(encoding_sentence, maxlen=length, padding='pre')\n",
    "print(padded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_model = keras.Sequential([\n",
    "    Embedding(my_vocab, 8, input_length=length),\n",
    "    Flatten(),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_model.compile(optimizer='adam',\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1/1 [==============================] - 1s 704ms/step - loss: 0.7007 - accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6984 - accuracy: 0.5000\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6961 - accuracy: 0.5000\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6938 - accuracy: 0.5000\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6916 - accuracy: 0.6667\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6893 - accuracy: 0.6667\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6871 - accuracy: 0.8333\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6849 - accuracy: 0.8333\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6827 - accuracy: 0.8333\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6804 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6782 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6760 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6739 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6717 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6695 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6673 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6651 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6629 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6607 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6585 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22149c00a88>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk_model.fit(padded_sentence,sentence_labels,epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loss: 0.656304\n",
      "Accuracy: 100.000000\n"
     ]
    }
   ],
   "source": [
    "modelloss, modelaccuracy = nltk_model.evaluate(padded_sentence,sentence_labels, verbose=0)\n",
    "\n",
    "print('Model loss: %f' % (modelloss))\n",
    "print('Accuracy: %f' % (modelaccuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_prediction = ['how are you Buddy',\n",
    "                       'I am good',\n",
    "                       'how is life going on',\n",
    "                       'That is going good'\n",
    "                      ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4, 12, 5, 21], [6, 26, 25], [4, 17, 18, 8, 1], [27, 17, 8, 25]]\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 30\n",
    "encoded = [one_hot(d, vocab_size) for d in sentence_prediction]\n",
    "print(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  4 12  5 21]\n",
      " [ 0  0  6 26 25]\n",
      " [ 4 17 18  8  1]\n",
      " [ 0 27 17  8 25]]\n"
     ]
    }
   ],
   "source": [
    "max_length = 5\n",
    "mypadded = pad_sequences(encoded, maxlen=max_length, padding='pre')\n",
    "print(mypadded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk_model.predict_classes(mypadded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Word Embedding model using gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\"Java is a class-based, object-oriented programming language that is designed to have as few implementation dependencies as possible\",\n",
    "             \"C++ is a general-purpose programming language created by Bjarne Stroustrup as an extension of the C programming language\",\n",
    "             \"Python is an interpreted, high-level and general-purpose programming language. Python's design philosophy emphasizes code readability with its notable use of significant indentation.\",\n",
    "             \"C is a general-purpose, procedural computer programming language supporting structured programming, lexical variable scope, and recursion, with a static type system. By design, C provides constructs that map efficiently to typical machine instructions.\",\n",
    "             \"JavaScript, often abbreviated as JS, is a programming language that conforms to the ECMAScript specification. JavaScript is high-level, often just-in-time compiled, and multi-paradigm. It has curly-bracket syntax, dynamic typing, prototype-based object-orientation, and first-class functions.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_sentences = []\n",
    "for i in sentences:\n",
    "    tokenized_sentences.append(word_tokenize(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Java', 'is', 'a', 'class-based', ',', 'object-oriented', 'programming', 'language', 'that', 'is', 'designed', 'to', 'have', 'as', 'few', 'implementation', 'dependencies', 'as', 'possible'], ['C++', 'is', 'a', 'general-purpose', 'programming', 'language', 'created', 'by', 'Bjarne', 'Stroustrup', 'as', 'an', 'extension', 'of', 'the', 'C', 'programming', 'language'], ['Python', 'is', 'an', 'interpreted', ',', 'high-level', 'and', 'general-purpose', 'programming', 'language', '.', 'Python', \"'s\", 'design', 'philosophy', 'emphasizes', 'code', 'readability', 'with', 'its', 'notable', 'use', 'of', 'significant', 'indentation', '.'], ['C', 'is', 'a', 'general-purpose', ',', 'procedural', 'computer', 'programming', 'language', 'supporting', 'structured', 'programming', ',', 'lexical', 'variable', 'scope', ',', 'and', 'recursion', ',', 'with', 'a', 'static', 'type', 'system', '.', 'By', 'design', ',', 'C', 'provides', 'constructs', 'that', 'map', 'efficiently', 'to', 'typical', 'machine', 'instructions', '.'], ['JavaScript', ',', 'often', 'abbreviated', 'as', 'JS', ',', 'is', 'a', 'programming', 'language', 'that', 'conforms', 'to', 'the', 'ECMAScript', 'specification', '.', 'JavaScript', 'is', 'high-level', ',', 'often', 'just-in-time', 'compiled', ',', 'and', 'multi-paradigm', '.', 'It', 'has', 'curly-bracket', 'syntax', ',', 'dynamic', 'typing', ',', 'prototype-based', 'object-orientation', ',', 'and', 'first-class', 'functions', '.']]\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "puncts = '#?!-,.;:–/—'\n",
    "for i in tokenized_sentences:\n",
    "    for j in i:\n",
    "        if j in puncts:\n",
    "            i.remove(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Java', 'is', 'a', 'class-based', 'object-oriented', 'programming', 'language', 'that', 'is', 'designed', 'to', 'have', 'as', 'few', 'implementation', 'dependencies', 'as', 'possible'], ['C++', 'is', 'a', 'general-purpose', 'programming', 'language', 'created', 'by', 'Bjarne', 'Stroustrup', 'as', 'an', 'extension', 'of', 'the', 'C', 'programming', 'language'], ['Python', 'is', 'an', 'interpreted', 'high-level', 'and', 'general-purpose', 'programming', 'language', 'Python', \"'s\", 'design', 'philosophy', 'emphasizes', 'code', 'readability', 'with', 'its', 'notable', 'use', 'of', 'significant', 'indentation'], ['C', 'is', 'a', 'general-purpose', 'procedural', 'computer', 'programming', 'language', 'supporting', 'structured', 'programming', 'lexical', 'variable', 'scope', 'and', 'recursion', 'with', 'a', 'static', 'type', 'system', 'By', 'design', 'C', 'provides', 'constructs', 'that', 'map', 'efficiently', 'to', 'typical', 'machine', 'instructions'], ['JavaScript', 'often', 'abbreviated', 'as', 'JS', 'is', 'a', 'programming', 'language', 'that', 'conforms', 'to', 'the', 'ECMAScript', 'specification', 'JavaScript', 'is', 'high-level', 'often', 'just-in-time', 'compiled', 'and', 'multi-paradigm', 'It', 'has', 'curly-bracket', 'syntax', 'dynamic', 'typing', 'prototype-based', 'object-orientation', 'and', 'first-class', 'functions']]\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "gensim_model = Word2Vec(tokenized_sentences,min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=82, size=100, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "print(gensim_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(gensim_model.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Java', 'is', 'a', 'class-based', 'object-oriented', 'programming', 'language', 'that', 'designed', 'to', 'have', 'as', 'few', 'implementation', 'dependencies', 'possible', 'C++', 'general-purpose', 'created', 'by', 'Bjarne', 'Stroustrup', 'an', 'extension', 'of', 'the', 'C', 'Python', 'interpreted', 'high-level', 'and', \"'s\", 'design', 'philosophy', 'emphasizes', 'code', 'readability', 'with', 'its', 'notable', 'use', 'significant', 'indentation', 'procedural', 'computer', 'supporting', 'structured', 'lexical', 'variable', 'scope', 'recursion', 'static', 'type', 'system', 'By', 'provides', 'constructs', 'map', 'efficiently', 'typical', 'machine', 'instructions', 'JavaScript', 'often', 'abbreviated', 'JS', 'conforms', 'ECMAScript', 'specification', 'just-in-time', 'compiled', 'multi-paradigm', 'It', 'has', 'curly-bracket', 'syntax', 'dynamic', 'typing', 'prototype-based', 'object-orientation', 'first-class', 'functions']\n"
     ]
    }
   ],
   "source": [
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.2726737e-03 -3.9100577e-04  4.1509629e-03 -2.6738062e-03\n",
      "  2.0580599e-03  4.7878576e-03  6.8650901e-04  2.8593536e-03\n",
      " -1.0317812e-03 -1.7796864e-04  4.7055432e-03 -4.3458277e-03\n",
      " -4.0599015e-03  2.4161523e-03 -3.3257129e-03 -4.0281690e-03\n",
      "  3.4138821e-03 -2.9849554e-03 -2.1566043e-03 -2.7361975e-04\n",
      " -6.8157836e-04  1.7237258e-03  8.3424780e-04 -1.2957718e-03\n",
      "  4.4362992e-03  3.2044107e-03 -1.6104579e-03 -3.7377467e-03\n",
      "  7.9233403e-04 -3.9141960e-03  4.9907132e-03 -3.8381451e-04\n",
      "  3.8080120e-03  2.7540969e-03  2.7503672e-03  2.9155274e-03\n",
      " -3.5451099e-05 -7.7986083e-04 -5.1021628e-04 -4.1540177e-03\n",
      "  2.2146155e-04 -3.8468298e-03 -3.2366705e-03  2.0303649e-03\n",
      " -7.6719525e-04  2.1604123e-03 -2.8733022e-03 -3.1325468e-03\n",
      "  7.4999298e-05 -3.5736377e-03  2.3921716e-03 -1.2540602e-03\n",
      "  1.8112283e-03 -1.9138756e-03 -3.5941773e-04 -3.7515636e-03\n",
      "  2.1603382e-03 -1.7413433e-05 -4.3483488e-03 -3.0741286e-03\n",
      " -1.3941372e-03  2.4732249e-03  4.0281713e-03 -1.9284337e-03\n",
      " -1.6206548e-04 -3.0281423e-03  1.6014768e-04  3.9490066e-03\n",
      "  1.5623664e-03 -1.5822984e-03 -3.8441315e-03 -3.7829638e-03\n",
      "  9.3852472e-04 -1.5969459e-03 -2.4783283e-03 -1.4326877e-03\n",
      " -2.1807270e-04 -1.9057420e-03  4.2197765e-03  1.7915854e-03\n",
      " -4.3537747e-03  2.9891524e-03  3.1886781e-03  3.4831152e-03\n",
      " -4.7432602e-04 -4.1141848e-05  2.1030174e-03  3.3550430e-04\n",
      " -5.2481919e-04 -4.9776197e-03 -9.5882948e-04 -6.3796667e-04\n",
      "  4.3457490e-03 -3.5281905e-03  3.2659960e-03 -4.1264645e-03\n",
      " -1.6026208e-03  8.4573997e-04  1.8321435e-03  4.6018558e-03]\n"
     ]
    }
   ],
   "source": [
    "print(gensim_model['is'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
